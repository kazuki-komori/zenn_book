---
title: "ãŠé¦´æŸ“ã¿ã®ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€ã„ã‚ã‚“ãªãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¦ã¿ã‚‹"
emoji: "ğŸ¡"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["æ©Ÿæ¢°å­¦ç¿’", "GBDT", "LightGBM", "NN"]
published: true
---


ã“ã®è¨˜äº‹ã¯ã€[Do'er Advent Calender](https://qiita.com/advent-calendar/2022/doer) ã®15æ—¥ç›®ã®è¨˜äº‹ã§ã™ã€‚

çš†ã•ã‚“ã“ã‚“ã«ã¡ã¯ï¼
Do'erä»£è¡¨ã®ã‹ãšã‚„ã‚“ã§ã™ã€‚

25æ—¥ã«ä»Šå¹´ä¸€å¹´ã®æŒ¯ã‚Šè¿”ã‚Šã¯ã™ã‚‹ã¨ã—ã¦ã€
æœ¬è¨˜äº‹ã§ã¯kaggleã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ãŠé¦´æŸ“ã¿ã®ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦è‰²ã‚“ãªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€ç²¾åº¦ã‚’æ¯”è¼ƒã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚

ã¾ãŸã€å®Ÿè£…ã‚’å«ã‚ãŸå†…å®¹ã¨ãªã£ã¦ã„ã¾ã™ã®ã§ã€æ°—ã«ãªã‚‹éƒ¨åˆ†ã¯ã‚¢ã‚³ãƒ¼ãƒ‡ã‚£ã‚ªãƒ³ã‚’å±•é–‹ã—ã¦ã¿ã¦ãã ã•ã„ï¼

# 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ä»¥ä¸‹ã®3ã¤ãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚
- train.csv: è¨“ç·´ãƒ‡ãƒ¼ã‚¿
- test.csv: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
- gender_submission.csv: ã‚µãƒ³ãƒ—ãƒ«ã®æå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«

å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä»¥ä¸‹ã§èª­ã¿è¾¼ã¿ã¾ã™ã€‚

```py
import pandas as pd
# å¯è¦–åŒ–ç”¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import matplotlib.pyplot as plt
import seaborn as sns

INPUT_DIR = "dataset"
# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df_train = pd.read_csv(f"{INPUT_DIR}/train.csv")
df_test = pd.read_csv(f"{INPUT_DIR}/test.csv")
```

# 2. ç°¡å˜ãªEDA (æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ)

ã‚³ãƒ³ãƒšã«å‚åŠ ã™ã‚‹ä¸Šã§ã€"ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹"ã®ã¯éå¸¸ã«å¤§äº‹ã ã¨ã‚ˆãè¨€ã‚ã‚Œã¾ã™ã€‚
è‰¯ã„è§£æ³•ã‚’å‡ºã™ãŸã‚ã®ãƒ’ãƒ³ãƒˆã‚‚ãƒ‡ãƒ¼ã‚¿ã«éš ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚

## 2-1. ã‚«ãƒ©ãƒ ä¸€è¦§ã®ç¢ºèª
```py
# DataFrame ã®æƒ…å ±ã‚’å‡ºåŠ›ã™ã‚‹
df_train.info()
```

```py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
```

ãµã‚€ãµã‚€ã€ã„ãã¤ã‹ã®ã‚«ãƒ©ãƒ ã§æ¬ æå€¤ãŒã‚ã‚Šãã†ã§ã™ã­ã€‚
è¦‹ã‚„ã™ã„ã‚ˆã†ã«å¯è¦–åŒ–ã—ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…
```py
# æ¬ æå€¤ã‚’é›†è¨ˆ
_summary = df_train.isna().mean().sort_values(ascending=False)
# æç”»
plt.subplots(figsize=(12, 6))
g = sns.barplot(x=_summary.index, y=_summary.values)
g.set_ylim(0, 1)
g.set_xticklabels(g.get_xticklabels(), rotation=30)
plt.show()
```
:::

![](https://storage.googleapis.com/zenn-user-upload/5a072745e733-20221216.png)
Cabinï¼ˆå®¢å®¤ç•ªå·ï¼‰,Ageï¼ˆå¹´é½¢ï¼‰ã€Embarkedï¼ˆå‡ºæ¸¯åœ°ï¼‰ã«æ¬ æå€¤ãŒã‚ã‚‹ã‚ˆã†ã§ã™ã­ã€‚
ç‰¹ã«ã€Cabinã«ã¤ã„ã¦ã¯æ¬ æå€¤ãŒåŠæ•°ä»¥ä¸Šã‚ã‚Šã¾ã™ã€‚

ã¤ã„ã§ã«ã€ã‚«ãƒ©ãƒ å†…å®¹ã‚’ã¾ã¨ã‚ã¦ã¿ã¾ã™

- PassengerId â€“ ä¹—å®¢è­˜åˆ¥ID
- Survived â€“ ç”Ÿå­˜ãƒ•ãƒ©ã‚°ï¼ˆ0=æ­»äº¡ã€1=ç”Ÿå­˜ï¼‰
- Pclass â€“ ãƒã‚±ãƒƒãƒˆã‚¯ãƒ©ã‚¹
- Name â€“ ä¹—å®¢ã®åå‰
- Sex â€“ æ€§åˆ¥ï¼ˆmale=ç”·æ€§ã€femaleï¼å¥³æ€§ï¼‰
- Age â€“ å¹´é½¢
- SibSp â€“ ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ã«åŒä¹—ã—ã¦ã„ã‚‹å…„å¼Ÿ/é…å¶è€…ã®æ•°
- Parch â€“ ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ã«åŒä¹—ã—ã¦ã„ã‚‹è¦ª/å­ä¾›ã®æ•°
- Ticket â€“ ãƒã‚±ãƒƒãƒˆç•ªå·
- Fare â€“ æ–™é‡‘
- Cabin â€“ å®¢å®¤ç•ªå·
- Embarked â€“ å‡ºæ¸¯åœ°

## 2-2. ç›®çš„å¤‰æ•°ã«é–¢ã™ã‚‹åˆ†æ
ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ã§ã¯Survivedï¼ˆç”Ÿå­˜ãƒ•ãƒ©ã‚°ï¼‰ã‚’ç›®çš„å¤‰æ•°ã¨ã—ã¦äºˆæ¸¬ã—ã¾ã™ã€‚
ã§ã¯ã€ã©ã‚Œãã‚‰ã„ã®å‰²åˆã®äººãŒç”Ÿå­˜ã—ã¦ã„ãŸã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ

:::detailsè©³ç´°ãªå®Ÿè£…
```py
# å‰²åˆã‚’è¨ˆç®—
_summary = df_train["Survived"].value_counts(normalize=True)
print(round(_summary, 2))
# å¯è¦–åŒ–
sns.countplot(data=df_train, x="Survived")
plt.show()
```
:::

```py
0    0.62
1    0.38
Name: Survived, dtype: float64
```
![](https://storage.googleapis.com/zenn-user-upload/6ce17779b8fb-20221216.png)
ç´„4å‰²ã®äººãŒç”Ÿå­˜ã—ãŸã‚ˆã†ã§ã™ã­ï¼
ã¨ã“ã‚ã§ã€ç”Ÿå­˜ç‡ã«ç”·å¥³ã®å·®ã¯ã‚ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ

:::detailsè©³ç´°ãªå®Ÿè£…
```py
# é›†è¨ˆ
_summary = df_train.groupby("Sex")["Survived"].value_counts(normalize=True)
print(round(_summary, 2))
# å¯è¦–åŒ–
sns.countplot(data=df_train, x="Sex", hue="Survived")
plt.show()
```
:::

```py
Sex     Survived
female  1           0.74
        0           0.26
male    0           0.81
        1           0.19
```
![](https://storage.googleapis.com/zenn-user-upload/f848d1965ab5-20221216.png)
å¥³æ€§ã®ç´„75%ãŒç”Ÿå­˜ã—ã¦ã„ã‚‹ã®ã«å¯¾ã—ã¦ã€ç”·æ€§ã®å‰²åˆãŒç´„20%ã—ã‹ç”Ÿå­˜ã§ãã¦ã„ã¾ã›ã‚“ï¼
å¥³æ€§ã®ç”Ÿå­˜ç‡ãŒã‹ãªã‚Šé«˜ã„å‚¾å‘ã«ã‚ã‚‹ã‚ˆã†ã§ã™ã€‚

ã§ã¯ã€ãƒã‚±ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã§ç”Ÿå­˜ç‡ã«å·®ã¯ã‚ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ

:::detailsè©³ç´°ãªå®Ÿè£…
```py
sns.countplot(data=df_train, x="Pclass", hue="Survived")
plt.show()
```
:::

![](https://storage.googleapis.com/zenn-user-upload/a0cd81cba840-20221216.png)
ãƒã‚±ãƒƒãƒˆã‚¯ãƒ©ã‚¹ãŒ3ã«ãªã£ãŸé€”ç«¯ã€ç”Ÿå­˜ç‡ãŒä¸€æ°—ã«ä½ä¸‹ã™ã‚‹ã‚ˆã†ã§ã™ã€‚

ä»–ã«ã‚‚è‰²ã€…é›†è¨ˆã®ä»•æ–¹ãŒã‚ã‚‹ã¨æ€ã†ã®ã§ã€æ°—ã«ãªã£ãŸç‰¹å¾´é‡ã¯å¯è¦–åŒ–ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼
å®Ÿéš›ã«è¦‹ã¦ã¿ã‚‹ã“ã¨ã§æ°—ã¥ããŒã‚ã£ãŸã‚Šã—ã¾ã™ã€‚
ä»Šå›ã¯åˆ†é‡ã®é–¢ä¿‚ä¸Šã€ã“ã‚Œãã‚‰ã„ã«ã—ã¦ãŠãã¾ã™ã€‚

# 3. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
## 3-1. BaseBlock
ä»Šå›ã¯ç‰¹å¾´é‡ã®ä½œæˆã®è¦‹é€šã—ã‚’è‰¯ãã™ã‚‹ãŸã‚ã€BaseBlockå½¢å¼ã®classã§ç®¡ç†ã—ã¾ã™ã€‚
å…¥å‡ºåŠ›ã‚’å¸¸ã«ä¸€å®šã«ã™ã‚‹ã®ã¨ã€trainãƒ‡ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’testã§é©ç”¨ã—ãŸã„ã¨ãã«éå¸¸ã«ä¾¿åˆ©ãªæ›¸ãæ–¹ã¨ãªã‚Šã¾ã™ã€‚

éå»ã®[AtmaCup #10](https://youtu.be/Nnx7enLds3Y?t=1125)ã«ã¦è©³ã—ãå‹•ç”»ã§è§£èª¬ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€èˆˆå‘³ãŒã‚ã‚‹æ–¹ã¯å‚ç…§ã„ãŸã ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ã€‚(å‚ç…§ï¼š18:45-)

@[youtube](Nnx7enLds3Y)
<!-- @[youtube](https://www.youtube.com/embed/Nnx7enLds3Y?start=1125) -->

ä»¥ä¸‹ã®åŸºåº•ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã€BaseBlockã‚’ä½œæˆã—ã¦ã„ãã¾ã™ã€‚
`fit` ãƒ¡ã‚½ãƒƒãƒ‰ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã®ã¿ã€`transform` ãƒ¡ã‚½ãƒƒãƒ‰ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚
ã“ã‚Œã«ã‚ˆã‚Šã€å®Ÿè£…å¿˜ã‚Œãªã©ã‚’é˜²ãã“ã¨ãŒã§ãã¾ã™ã€‚
ã¾ãŸã€å¼•æ•°ã¨ã—ã¦`parent_blocks`ã‚’ä¸ãˆã¦ã‚ã’ã‚‹ã“ã¨ã§ã€è¦ªãƒ–ãƒ­ãƒƒã‚¯ã‚’å‚ç…§ã—ãŸå®Ÿè£…ã§ãã¾ã™ã€‚

```py
class AbstractBaseBlock:
  def __init__(self, parent_blocks = None):
    self.parent_blocks = [] if parent_blocks is None else parent_blocks

  def fit(self, input_df: pd.DataFrame, y=None):        
    return self.transform(input_df)

  def transform(self, input_df: pd.DataFrame) -> pd.DataFrame:
    raise NotImplementedError()
```

ä»¥ä¸‹ã¯å®Ÿè£…ã«ä½¿ç”¨ã™ã‚‹é–¢æ•°ã®å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆæ¸¬ã™ã‚‹Timerã¨ã€BaseBlockã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®é–¢æ•°ã§ã™ã€‚
è©³ã—ã„è§£èª¬ã¯çœãã¾ã™ãŒã€ãƒ­ã‚°ã¨ã—ã¦å®Ÿè¡Œæ™‚é–“ãŒå‡ºåŠ›ã•ã‚Œã€ç‰¹å¾´é‡ã‚’ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã¯ã‚«ãƒ©ãƒ åã«ãƒ–ãƒ­ãƒƒã‚¯åã®`suffix`ã‚’ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…
```py
# ã‚¿ã‚¤ãƒãƒ¼
class Timer:
  def __init__(self, logger=None, format_str="{:.3f}[s]", prefix=None, suffix=None, sep=" "):
    if prefix:
      format_str = str(prefix) + sep + format_str
    if suffix:
      format_str = format_str + sep + str(suffix)
    self.format_str = format_str
    self.logger = logger
    self.start = None
    self.end = None

  @property
  def duration(self):
    if self.end is None:
      return 0
    return self.end - self.start

  def __enter__(self):
    self.start = time()

  def __exit__(self, exc_type, exc_val, exc_tb):
    self.end = time()
    out_str = self.format_str.format(self.duration)
    if self.logger:
      self.logger.info(out_str)
    else:
      print(out_str)

# BaseBlock å®Ÿè¡Œé–¢æ•°
def run_blocks(input_df, blocks, y=None, test=False):
  df_out = pd.DataFrame()

  for block in blocks:
    if block.parent_blocks:
      _df = run_blocks(input_df=input_df, blocks=block.parent_blocks, y=y, test=test)
    else:
      _df = input_df

    with Timer(prefix='\t- {}'.format(str(block))):
      if not test:
        out_i = block.fit(_df, y=y)
      else:
        out_i = block.transform(_df)

    assert len(input_df) == len(out_i), block
    name = block.__class__.__name__
    df_out = pd.concat([df_out, out_i.add_suffix(f"@{name}")], axis=1)

  return df_out
```
:::

## 3-2. ç‰¹å¾´é‡ã®ä½œæˆ

ã“ã“ã‹ã‚‰ã¯ã€ç‰¹å¾´é‡ã®ä½œæˆã—ã¾ã™ã€‚
ä¸»ã«ä»¥ä¸‹ã®ç‰¹å¾´é‡ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚

- é‡çš„ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ãŸã‚‚ã®
- LabelEncodingï¼ˆè³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªæ•°å€¤ã§è¡¨ç¾ã—ãŸã‚‚ã®ï¼‰
- CountEncodingï¼ˆè³ªçš„ãƒ‡ãƒ¼ã‚¿ã®ç™»å ´å›æ•°ã‚’æ•°å€¤ã§è¡¨ç¾ã—ãŸã‚‚ã®ï¼‰
- OneHotEncodingï¼ˆè³ªçš„ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡ã”ã¨ã§ã‚’ã€0ã¾ãŸã¯1ã§è¡¨ç¾ã—ãŸã‚‚ã®ï¼‰
- TargetEncodingã®å¹³å‡ã€æ¨™æº–åå·®ï¼ˆç›®çš„å¤‰æ•°ã‚’è³ªçš„ãƒ‡ãƒ¼ã‚¿ã§é›†è¨ˆã—ãŸã‚‚ã®ï¼‰
- å„åˆ—ã®äº¤äº’ä½œç”¨
- æ­ä¹—è€…ã®æ°åã«é–¢ã™ã‚‹æ•¬ç§°æƒ…å ±
- ä¹—èˆ¹ä½ç½®ã«é–¢ã™ã‚‹æƒ…å ±

ã¾ãŸã€å„ã‚¯ãƒ©ã‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆã«å®Ÿè£…å†…å®¹ã‚’ç°¡å˜ã«è¨˜ã—ã¦ã„ã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…
```py
class OriginalColumnBlock(AbstractBaseBlock):
    """æŒ‡å®šã—ãŸã‚«ãƒ©ãƒ ã‚’ãã®ã¾ã¾è¿”ã™"""
    def __init__(self, target_col: str) -> None:
        super().__init__()
        self.target_col = target_col

    def transform(self, df_input: pd.DataFrame):
        return pd.DataFrame(df_input[self.target_col])


class DummyValiableBlock(AbstractBaseBlock):
    """ãƒ€ãƒŸãƒ¼å¤‰æ•°ã®ä½œæˆ"""
    def __init__(self, target_col: str, drop_first: bool, **kwrgs) -> None:
        super().__init__(**kwrgs)
        self.target_col = target_col
        self.drop_first = drop_first
    
    def fit(self, df_input: pd.DataFrame, y=None):
        df_train_out = pd.get_dummies(df_input[self.target_col], drop_first=self.drop_first).add_prefix(f"{self.target_col}_")
        self.train_column_ = df_train_out.columns
        return df_train_out

    def transform(self, df_input: pd.DataFrame):
        return pd.get_dummies(df_input[self.target_col], drop_first=self.drop_first).add_prefix(f"{self.target_col}_").reindex(columns=self.train_column_, fill_value=0)


class LabelEncodingBlock(AbstractBaseBlock):
    """LabelEncoding"""
    def __init__(self, target_col: str) -> None:
        super().__init__()
        self.le = LabelEncoder()
        self.target_col = target_col

    def fit(self, df_input: pd.DataFrame, y=None):
        self.le.fit(df_input[self.target_col])
        return self.transform(df_input)

    def transform(self, df_input: pd.DataFrame):
        return pd.DataFrame({
            self.target_col: self.le.fit_transform(df_input[self.target_col])
        })


class CountEncodingBlock(AbstractBaseBlock):
    """CountEncoding"""
    def __init__(self, target_col: str, **kwrgs) -> None:
        super().__init__(**kwrgs)
        self.target_col = target_col

    def fit(self, df_input: pd.DataFrame, y=None):
        self.vc_ = df_input[self.target_col].value_counts()
        return self.transform(df_input)

    def transform(self, df_input: pd.DataFrame):
        return pd.DataFrame(df_input[self.target_col].map(self.vc_))


class TargetEncodeBlock(AbstractBaseBlock):
    """Target Encoding"""
    def __init__(self, target_col, agg: List, **kwrgs) -> None:
        super().__init__(**kwrgs)
        self.target = target_col
        self.agg = agg

    def fit(self, df_input: pd.DataFrame, y):
        self.dics_ = []
        if y not in df_input.columns:
            df_input = pd.concat([df_input, df_train[y]], axis=1)
        fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)
        cv = fold.split(df_input[self.target], df_input[self.target])
        df_out = pd.DataFrame(index=df_input.index)
        for idx_feature, idx_valid in cv:
            df_feature = df_input[df_input.index.isin(idx_feature)]
            df_valid = df_input[df_input.index.isin(idx_valid)]
            _dic = df_feature.groupby(self.target)[y].agg(self.agg).to_dict()
            self.dics_.append(_dic)
            for agg in self.agg:
                df_out.loc[idx_valid, f"target={self.target}_agg_func={agg}"] = df_valid[self.target].map(_dic[agg])
        return df_out
	
    def transform(self, df_input: pd.DataFrame):
        df_out = pd.DataFrame()
        for agg in self.agg:
            _df = pd.DataFrame()
            for i, _dic in enumerate(self.dics_):
                _df[i] = df_input[self.target].map(_dic[agg])
            df_out[f"target={self.target}_agg_func={agg}"] = _df.mean(axis=1)
        return df_out


class AddBlock(AbstractBaseBlock):
    """æŒ‡å®šã—ãŸã‚«ãƒ©ãƒ ã®å’Œã‚’ç®—å‡ºã™ã‚‹"""
    def __init__(self, col1: str, col2: str, **kwrgs) -> None:
        super().__init__(**kwrgs)
        self.col1 = col1
        self.col2 = col2

    def transform(self, df_input: pd.DataFrame):
        return pd.DataFrame({
            f"{self.col1}+{self.col2}": df_input[self.col1] + df_input[self.col2]
        })

class NameTitleBlock(AbstractBaseBlock):
    """æ•¬ç§°ã«é–¢ã™ã‚‹ç‰¹å¾´é‡"""
    def __init__(self) -> None:
        super().__init__()

    def transform(self, df_input: pd.DataFrame):
        df_input['Title'] = df_input['Name'].map(lambda x: x.split(', ')[1].split('. ')[0])
        df_input['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer', inplace=True)
        df_input['Title'].replace(['Don', 'Sir',  'the Countess', 'Lady', 'Dona', 'Jonkheer'], 'Royalty', inplace=True)
        df_input['Title'].replace(['Mme', 'Ms'], 'Mrs', inplace=True)
        df_input['Title'].replace(['Mlle'], 'Miss', inplace=True)
        return pd.DataFrame(df_input['Title'])


class DeckBlock(AbstractBaseBlock):
    """ä¹—èˆ¹ä½ç½®ã«é–¢ã™ã‚‹ç‰¹å¾´é‡"""
    def __init__(self) -> None:
        super().__init__()

    def transform(self, df_input: pd.DataFrame):
        return pd.DataFrame({"Deck": df_input['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')})


class MultiGroupAggBlock(AbstractBaseBlock):
    """è¤‡æ•°ã®ã‚«ãƒ©ãƒ ã®ã‚°ãƒ«ãƒ¼ãƒ—é›†è¨ˆã«é–¢ã™ã‚‹ç‰¹å¾´é‡"""
    def __init__(self, group_by: List) -> None:
        super().__init__()
        self.group_by = group_by

    def transform(self, df_input: pd.DataFrame):
        return pd.DataFrame({"Deck": df_input['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')})

############################# ç‰¹å¾´é‡ã®ä½œæˆ
blocks = [
    *[OriginalColumnBlock(target_col) for target_col in ["Pclass", "Age", "SibSp", "Parch", "Fare"]],
    *[DummyValiableBlock(target_col, drop_first=False) for target_col in ["Sex"]],
    *[DummyValiableBlock(target_col, drop_first=False) for target_col in ["Embarked"]],
    *[LabelEncodingBlock(target_col) for target_col in ["Cabin", "Ticket"]],
    *[CountEncodingBlock(target_col) for target_col in ["Cabin", "Pclass", "Age", "SibSp", "Embarked", "Ticket"]],
    *[TargetEncodeBlock(target_col, ["mean", "std"]) for target_col in ["Sex", "SibSp", "Parch", "Ticket"]],
    TargetEncodeBlock(target_col="SibSp+Parch@AddBlock", agg=["mean", "std"], parent_blocks=[AddBlock(col1="SibSp", col2="Parch")]),
    TargetEncodeBlock(target_col="Title@NameTitleBlock", agg=["mean", "std"], parent_blocks=[NameTitleBlock()]),
    DummyValiableBlock(target_col="Title@NameTitleBlock", drop_first=False, parent_blocks=[NameTitleBlock()]),
    CountEncodingBlock(target_col="Title@NameTitleBlock", parent_blocks=[NameTitleBlock()]),
    TargetEncodeBlock(target_col="Deck@DeckBlock", agg=["mean", "std"], parent_blocks=[DeckBlock()]),
    DummyValiableBlock(target_col="Deck@DeckBlock", drop_first=False, parent_blocks=[DeckBlock()]),
    CountEncodingBlock(target_col="Deck@DeckBlock", parent_blocks=[DeckBlock()]),
]

df_train_feature = run_blocks(df_train.copy(), blocks, y="Survived")
df_test_feature = run_blocks(df_test.copy(), blocks, test=True)

```
:::

:::detailså®Ÿè¡Œçµæœ
```py
	- <__main__.OriginalColumnBlock object at 0x7fa46863ee20> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa4686430a0> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa468643190> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa4686431f0> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa4686433a0> 0.000[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643400> 0.001[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643460> 0.000[s]
	- <__main__.LabelEncodingBlock object at 0x7fa4686434c0> 0.000[s]
	- <__main__.LabelEncodingBlock object at 0x7fa468643550> 0.001[s]
	- <__main__.CountEncodingBlock object at 0x7fa4686435e0> 0.001[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643640> 0.001[s]
	- <__main__.CountEncodingBlock object at 0x7fa4686436a0> 0.001[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643700> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643760> 0.001[s]
	- <__main__.CountEncodingBlock object at 0x7fa4686437c0> 0.001[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643820> 0.009[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643880> 0.008[s]
	- <__main__.TargetEncodeBlock object at 0x7fa4686438e0> 0.008[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643940> 0.013[s]
	- <__main__.AddBlock object at 0x7fa46863ed60> 0.000[s]
	- <__main__.TargetEncodeBlock object at 0x7fa4686439d0> 0.008[s]
	- <__main__.NameTitleBlock object at 0x7fa468643a30> 0.002[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643a90> 0.009[s]
	- <__main__.NameTitleBlock object at 0x7fa468643af0> 0.002[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643b50> 0.000[s]
	- <__main__.NameTitleBlock object at 0x7fa468643bb0> 0.002[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643c10> 0.001[s]
	- <__main__.DeckBlock object at 0x7fa468643c70> 0.001[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643cd0> 0.009[s]
	- <__main__.DeckBlock object at 0x7fa468643d30> 0.001[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643d90> 0.000[s]
	- <__main__.DeckBlock object at 0x7fa468643df0> 0.001[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643e50> 0.001[s]
	- <__main__.OriginalColumnBlock object at 0x7fa46863ee20> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa4686430a0> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa468643190> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa4686431f0> 0.000[s]
	- <__main__.OriginalColumnBlock object at 0x7fa4686433a0> 0.000[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643400> 0.000[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643460> 0.000[s]
	- <__main__.LabelEncodingBlock object at 0x7fa4686434c0> 0.000[s]
	- <__main__.LabelEncodingBlock object at 0x7fa468643550> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa4686435e0> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643640> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa4686436a0> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643700> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643760> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa4686437c0> 0.000[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643820> 0.004[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643880> 0.004[s]
	- <__main__.TargetEncodeBlock object at 0x7fa4686438e0> 0.004[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643940> 0.005[s]
	- <__main__.AddBlock object at 0x7fa46863ed60> 0.000[s]
	- <__main__.TargetEncodeBlock object at 0x7fa4686439d0> 0.004[s]
	- <__main__.NameTitleBlock object at 0x7fa468643a30> 0.002[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643a90> 0.004[s]
	- <__main__.NameTitleBlock object at 0x7fa468643af0> 0.001[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643b50> 0.000[s]
	- <__main__.NameTitleBlock object at 0x7fa468643bb0> 0.002[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643c10> 0.000[s]
	- <__main__.DeckBlock object at 0x7fa468643c70> 0.000[s]
	- <__main__.TargetEncodeBlock object at 0x7fa468643cd0> 0.004[s]
	- <__main__.DeckBlock object at 0x7fa468643d30> 0.000[s]
	- <__main__.DummyValiableBlock object at 0x7fa468643d90> 0.001[s]
	- <__main__.DeckBlock object at 0x7fa468643df0> 0.000[s]
	- <__main__.CountEncodingBlock object at 0x7fa468643e50> 0.000[s]
```
:::

## 3-3. æ¬ æå€¤è£œå®Œ
EDAã§ã‚‚ç¢ºèªã—ãŸé€šã‚Šã€å¹´é½¢ã‚„å‡ºæ¸¯åœ°ã«æ¬ æå€¤ãŒã‚ã‚Šã¾ã—ãŸã€‚

kaggleãªã©ã§ä¸€èˆ¬çš„ã«åºƒãç”¨ã„ã‚‰ã‚Œã¦ã„ã‚‹ã€LightGBMãªã©ã®å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚’ç”¨ã„ãŸæ±ºå®šæœ¨ã§ã¯æ¬ æå€¤è£œå®Œã‚’ã—ãªãã¦ã‚‚ã€å­¦ç¿’ã§ãã¾ã™ã€‚
ã—ã‹ã—ãªãŒã‚‰ã€æ¬ æå€¤ã‚’åˆ¥ã®ç‰¹å¾´é‡ã‹ã‚‰äºˆæ¸¬ã—ã¦ã‚ã’ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé«˜ç²¾åº¦ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
ã¾ãŸã€Neural Networkãªã©æ¬ æå€¤ãŒã‚ã‚‹ã¨ã†ã¾ãå­¦ç¿’ã§ããªã„ãƒ¢ãƒ‡ãƒ«ã‚‚å¤šæ•°å­˜åœ¨ã—ã¾ã™ã€‚

ãã“ã§ã€ä»Šå›ã¯LightGBMã‚’ç”¨ã„ãŸæ¬ æå€¤è£œå®Œã—ã¾ã™ã€‚

:::detailså®Ÿè£…é–¢æ•°ã®è©³ç´°ãªèª¬æ˜
ã¾ãšã€fit() ãƒ¡ã‚½ãƒƒãƒ‰ã§æ¬ æå€¤ãŒã‚ã‚‹åˆ—ã‚’æŒ‡å®šã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚
æ¬ æå€¤ã®ã‚ã‚‹è¡Œã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ã€ãã®ä»–ã®è¡Œã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚
ã“ã®ã¨ãã€early_stopping_roundsã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€æŒ‡å®šã—ãŸãƒ©ã‚¦ãƒ³ãƒ‰æ•°ã§æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦ãŒæ”¹å–„ã—ãªããªã£ãŸã¨ãã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åœæ­¢ã§ãã¾ã™ã€‚

ãã®å¾Œã€transform() ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§ã€æŒ‡å®šã•ã‚ŒãŸåˆ—ã®æ¬ æå€¤ã‚’è£œå®Œã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã—ã¾ã™ã€‚
ã“ã®ã¨ãã€fit() ãƒ¡ã‚½ãƒƒãƒ‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€æ¬ æå€¤ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚
_create_ds() ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã§ã™ã€‚
fit() ãŠã‚ˆã³transform() ãƒ¡ã‚½ãƒƒãƒ‰ã§å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
:::

:::detailsè©³ç´°ãªå®Ÿè£…
```py
import lightgbm as lgbm
from tqdm.notebook import tqdm
from sklearn.model_selection import train_test_split

class LGBMImputer:
    def __init__(
            self,
            feature_cols: List,
            target_cols: List,
            early_stopping_rounds: int = 20
        ) -> None:
        self.feature_cols = feature_cols
        self.target_cols = target_cols
        self.early_stopping_rounds = early_stopping_rounds
        self.models: Dict[str, lgbm.Booster] = {}
    
    def fit(self, df_input: pd.DataFrame):
        for target_col in tqdm(self.target_cols, desc="train lgbm models..."):
            # æ¬ æã®è¡Œã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã™ã‚‹
            train_ds, valid_ds = self._create_ds(df_input, target_col)
            params = self._feature_type_checker(train_ds.label)
            # äºˆæ¸¬
            model = lgbm.train(
                {**params, "verbosity": -1},
                num_boost_round=500000,
                train_set=train_ds,
                callbacks=[
                    lgbm.early_stopping(stopping_rounds=self.early_stopping_rounds, verbose=-1)
                ],
                valid_sets=[valid_ds]
            )
            self.models[target_col] = model
        
        return self.transform(df_input)
    

    def transform(self, df_input: pd.DataFrame):
        df_input_cp = df_input.copy(deep=True)

        for target_col in tqdm(self.target_cols, desc="predict from lgbm models..."):
            if df_input[target_col].isnull().sum() > 0:
                # æ¬ æã®è¡Œã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã™ã‚‹
                _, valid_ds = self._create_ds(df_input, target_col)
                df_input_cp.loc[valid_ds.data.index, target_col] = self.models[target_col].predict(valid_ds.data, num_iteration=self.models[target_col].best_iteration)
        return df_input_cp
    

    def _create_ds(self, df_input: pd.DataFrame, target_col: str):
            # æ¬ æã®è¡Œã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã™ã‚‹ / æ¬ æè£œå®Œã™ã‚‹ã‚«ãƒ©ãƒ ã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹
            idx_miss = df_input[df_input[target_col].isnull()].index
            if len(idx_miss) != 0:
                train_ds = lgbm.Dataset(
                    df_input[~df_input.index.isin(idx_miss)][self.feature_cols],
                    df_input[~df_input.index.isin(idx_miss)][target_col],
                )
                valid_ds = lgbm.Dataset(
                    df_input[df_input.index.isin(idx_miss)][self.feature_cols],
                    df_input[df_input.index.isin(idx_miss)][target_col],
                )
            else:
                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«æ¬ æå€¤ãŒãªã„ã¨ã
                df_train, df_valid = train_test_split(df_input, test_size=.2, random_state=712)
                train_ds = lgbm.Dataset(
                    df_input[df_input.index.isin(df_train.index)][self.feature_cols],
                    df_input[df_input.index.isin(df_train.index)][target_col],
                )
                valid_ds = lgbm.Dataset(
                    df_input[df_input.index.isin(df_valid.index)][self.feature_cols],
                    df_input[df_input.index.isin(df_valid.index)][target_col],
                )
            return train_ds, valid_ds
    
    def _feature_type_checker(self, series: pd.Series) -> dict:
        # è‡ªå‹•ã§å‹ã‚’åˆ¤å®šã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿”ã™
        if pd.api.types.is_numeric_dtype(series):
            # é€£ç¶šå¤‰æ•°ã®ã¨ã
            return {
                'objective': 'regression'
            }
        else:
            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã¨ã
            nuni = series.dropna().nunique()
            if nuni == 2:
                return {
                    'objective': 'binary'
                }
            elif nuni > 2:
                return {
                    'objective': 'multiclass',
                    'num_class': nuni + 1
                }
```
:::

```py
# trainã®æ¬ æå€¤ã®åˆ—ã‚’å–å¾—
_summary_train = df_train_feature.isnull().sum()
# testã®æ¬ æå€¤ã®åˆ—ã‚’å–å¾—
_summary_test = df_test_feature.isnull().sum()
# trainã¨testã®æ¬ æå€¤ã®åˆ—ã‚’å’Œé›†åˆã¨ã—ã¦å–ã‚‹
target_cols = set(_summary_train[_summary_train > 0].index) | set(_summary_test[_summary_test > 0].index)
# trainã¨testã®æ¬ æå€¤ã§ã¯ãªã„åˆ—ã‚’å–ã‚‹
feature_cols = set(df_test_feature.columns) - target_cols

# æ¬ æå€¤è£œå®Œ
imputer = LGBMImputer(feature_cols, target_cols)
df_train_feature = imputer.fit(df_train_feature)
df_test_feature = imputer.transform(df_test_feature)

# ç›®çš„å¤‰æ•°ã‚’ä»˜ä¸
df_train_feature["Survived"] = df_train["Survived"]

# ä¿å­˜
df_train_feature.to_csv(f"{OUTPUT_DIR}/002_train.csv", index=False)
df_test_feature.to_csv(f"{OUTPUT_DIR}/002_test.csv", index=False)

df_train_feature.head(5)
```

# 4. ã„ã–ã€ãƒ¢ãƒ‡ãƒ«ã«å­¦ç¿’ã•ã›ã‚‹ï¼
ã“ã“ã¾ã§ã€ãƒ‡ãƒ¼ã‚¿ã®æŠŠæ¡ã¨ç‰¹å¾´é‡ã®ä½œã—ã¾ã—ãŸã€‚
ã‚ˆã†ã‚„ãæœ¬é¡Œã®ç²¾åº¦ã®æ¯”è¼ƒã«å…¥ã‚Šã¾ã™ï¼
æ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŸã¡ã¯ä»¥ä¸‹ã®5ã¤ã«ãªã‚Šã¾ã™ã€‚
- LightGBM
- XGBoost
- NN (Neural Network)
- SVM (Support Vector Machines)
- k-NN (k-Nearest Neighbor)

ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®ç›®çš„å¤‰æ•°ã«å¯¾ã—ã¦`StratifiedKFold, k=5`ï¼ˆ5åˆ†å‰²å±¤åŒ–æŠ½å‡ºï¼‰ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
â€»ä»Šå›ã¯kNNä»¥å¤–ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¾ã§ã¯å®Ÿè£…ã—ã¦ã„ãªã„ã®ã§ã€ç²¾åº¦ã«å¤šå°‘ã®èª¤å·®ã‚’ç”Ÿã‚€å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

<!-- ===================================================== -->
## 4-1. LightGBM
LightGBMã¯ã€å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°æ±ºå®šæœ¨ï¼ˆGBDTï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
GBDTã¯ã€è¤‡æ•°ã®æ±ºå®šæœ¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹æ‰‹æ³•ã§ã™ã€‚
LightGBMã¯ã€GBDTã‚’ã•ã‚‰ã«é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®æ§˜ã€…ãªæ”¹å–„ã‚’æ–½ã—ã¦ãŠã‚Šã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚é«˜é€Ÿã«å­¦ç¿’ã§ãã¾ã™ã€‚
ã¾ãŸã€å›å¸°ã‚„åˆ†é¡å•é¡Œãªã©å¤šãã®ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ãŠã‚Šã€ç‰¹ã«kaggleãªã©ã®æ©Ÿæ¢°å­¦ç¿’ã‚³ãƒ³ãƒšã§ã¯å¸¸é€£ã®ãƒ¢ãƒ‡ãƒ«ã¨ãªã£ã¦ã„ã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ï¼‰
```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import lightgbm as lgbm

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score

import shap
# å¯è¦–åŒ–ã®ãŸã‚ã® javascript ã‚’èª­ã¿è¾¼ã¿
shap.initjs()
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼‰
```py
SEED = 712

########################## ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df_train = pd.read_csv("../features/002_train.csv")
df_test = pd.read_csv("../features/002_test.csv")

df_train_lab = df_train.pop("Survived")
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
```py
GBM_PARAMS = {
  # ç›®çš„é–¢æ•°. ã“ã‚Œã®æ„å‘³ã§æœ€å°ã¨ãªã‚‹ã‚ˆã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ã—ã¾ã™. 
  "objective": "binary", 

    # å­¦ç¿’ç‡. å°ã•ã„ã»ã©ãªã‚ã‚‰ã‹ãªæ±ºå®šå¢ƒç•ŒãŒä½œã‚‰ã‚Œã¦æ€§èƒ½å‘ä¸Šã«ç¹‹ãŒã‚‹å ´åˆãŒå¤šã„ã§ã™ã€
  # ãŒãã‚Œã ã‘æœ¨ã‚’ä½œã‚‹ãŸã‚å­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
  "learning_rate": .005,

  # L2 Reguralization
  "reg_lambda": .1,
  # ã“ã¡ã‚‰ã¯ L1 
  "reg_alpha": .1,

  # æœ¨ã®æ·±ã•. æ·±ã„æœ¨ã‚’è¨±å®¹ã™ã‚‹ã»ã©ã‚ˆã‚Šè¤‡é›‘ãªäº¤äº’ä½œç”¨ã‚’è€ƒæ…®ã™ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™
  "max_depth": 7, 

  # æœ¨ã®æœ€å¤§æ•°. early_stopping ã¨ã„ã†æ çµ„ã¿ã§æœ¨ã®æ•°ã¯åˆ¶å¾¡ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã®ã§ã¨ã¦ã‚‚å¤§ãã„å€¤ã‚’æŒ‡å®šã—ã¦ãŠãã¾ã™.
  "n_estimators": 50000, 

  # æœ¨ã‚’ä½œã‚‹éš›ã«è€ƒæ…®ã™ã‚‹ç‰¹å¾´é‡ã®å‰²åˆ. 1ä»¥ä¸‹ã‚’æŒ‡å®šã™ã‚‹ã¨ç‰¹å¾´ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æ¬ è½ã•ã›ã¾ã™ã€‚å°ã•ãã™ã‚‹ã“ã¨ã§, ã¾ã‚“ã¹ã‚“ãªãç‰¹å¾´ã‚’ä½¿ã†ã¨ã„ã†åŠ¹æœãŒã‚ã‚Šã¾ã™.
  "colsample_bytree": .7, 

  # æœ€å°åˆ†å‰²ã§ã®ãƒ‡ãƒ¼ã‚¿æ•°. å°ã•ã„ã¨ã‚ˆã‚Šç´°ã‹ã„ç²’åº¦ã®åˆ†å‰²æ–¹æ³•ã‚’è¨±å®¹ã—ã¾ã™.
  "min_child_samples": 20,

  # bagging ã®é »åº¦ã¨å‰²åˆ
  "subsample_freq": 3,
  "subsample": .9,

  # ç‰¹å¾´é‡è¦åº¦è¨ˆç®—ã®ãƒ­ã‚¸ãƒƒã‚¯(å¾Œè¿°)
  "importance_type": "gain",
  
  "early_stopping_rounds": 50,
  "verbose_eval": 200,
  
  # "metrics": "auc",
  "verbose": -1,
  "seed": SEED,
  
  'device_type': 'gpu',
}
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆå­¦ç¿’ï¼‰
```py
def fit_lgbm(X: pd.DataFrame, y, cv, params):
    oof_pred = np.zeros(len(X), dtype=np.float32)
    models = []
    scores = []

    for i, (idx_train, idx_valid) in enumerate(cv):
        x_train, y_train = X[X.index.isin(idx_train)], y[idx_train]
        x_valid, y_valid = X[X.index.isin(idx_valid)], y[idx_valid]

        ds_train = lgbm.Dataset(x_train, y_train)
        ds_valid = lgbm.Dataset(x_valid, y_valid)

        with Timer(prefix=f"fit ========== Fold: {i + 1}"):
            model = lgbm.train(
                params,
                ds_train,
                valid_names=["train, valid"],
                valid_sets=[ds_train, ds_valid]
            )

            pred_i = model.predict(x_valid, num_iteration=model.best_iteration)
            oof_pred[idx_valid] = pred_i

            score = accuracy_score(y_valid, pred_i.round())
            print(f" - fold{i + 1} - {score:.4f}")

            scores.append(score)
            models.append(model)
        
    score = accuracy_score(y, oof_pred.round())
    print("=" * 50)
    print(f"FINISH: Whole Score: {score:.4f}")

    return oof_pred, models, score
```
:::

### 4-1-a. Cross Validationï¼ˆäº¤å·®æ¤œè¨¼ã€ä»¥é™ã§ã¯ CVï¼‰ã®çµæœ
```py
 - fold1 - 0.8324
fit ========== Fold: 1 1.008[s]
 - fold2 - 0.8427
fit ========== Fold: 2 0.860[s]
 - fold3 - 0.8989
fit ========== Fold: 3 1.776[s]
 - fold4 - 0.7865
fit ========== Fold: 4 0.923[s]
 - fold5 - 0.8708
fit ========== Fold: 5 1.495[s]
==================================================
FINISH: Whole Score: 0.8462
```

### 4-1-b. ç‰¹å¾´é‡ã®é‡è¦åº¦ã®å¯è¦–åŒ–
ãƒã‚±ãƒƒãƒˆç•ªå·ã®LabelEncodingãŒæœ€ã‚‚åŠ¹ã„ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚
ã¾ãŸã€å¹´é½¢ã‚‚é‡è¦ãªç‰¹å¾´é‡ã«ãªã£ã¦ãã†ã§ã™ã­ï¼

:::detailsè©³ç´°ãªå®Ÿè£…
```py
def visualize_importance(models, feat_train_df, top_n):
    """lightGBM ã® model é…åˆ—ã® feature importance ã‚’ plot ã™ã‚‹
    CVã”ã¨ã®ãƒ–ãƒ¬ã‚’ boxen plot ã¨ã—ã¦è¡¨ç¾

    args:
        models:
            List of lightGBM models
        feat_train_df:
            å­¦ç¿’æ™‚ã«ä½¿ã£ãŸ DataFrame
    """
    feature_importance_df = pd.DataFrame()
    for i, model in enumerate(models):
        _df = pd.DataFrame()
        _df["feature_importance"] = model.feature_importance(importance_type='split')
        _df["column"] = feat_train_df.columns
        _df["fold"] = i + 1
        feature_importance_df = pd.concat([feature_importance_df, _df], 
                                          axis=0, ignore_index=True)

    order = feature_importance_df.groupby("column")\
        .sum()[["feature_importance"]]\
        .sort_values("feature_importance", ascending=False).index[:top_n]

    fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))
    sns.boxenplot(data=feature_importance_df, 
                  x="feature_importance", 
                  y="column", 
                  order=order, 
                  ax=ax, 
                  palette="viridis", 
                  orient="h")
    ax.tick_params(axis="x", rotation=90)
    ax.set_title("Importance")
    ax.grid()
    fig.tight_layout()
    plt.show()
    return fig, ax

fig, ax = visualize_importance(models, df_train, 100)
```
:::

![](https://storage.googleapis.com/zenn-user-upload/d0f2372c053d-20221216.png)

### 4-1-c. äºˆæ¸¬å€¤ã®åˆ†å¸ƒã‚’è¦‹ã‚‹

:::detailsè©³ç´°ãªå®Ÿè£…
```py
plt.subplots(figsize=(8, 6))
ax = sns.distplot(oof, bins=30, label="train out of fold")
ax = sns.distplot(pred_prob, bins=30, label="test predict")
ax.legend()
plt.show()
```
:::

![](https://storage.googleapis.com/zenn-user-upload/9d40f1124261-20221216.png)

### 4-1-d. Shapã§ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’è¦‹ã‚‹
:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆShapã§ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’è¦‹ã‚‹ï¼‰
```py
explainer = shap.TreeExplainer(models[0])

shap_values = explainer.shap_values(df_train)
shap.summary_plot(shap_values=shap_values[0], features=df_train)
```
:::

![](https://storage.googleapis.com/zenn-user-upload/c74be462613c-20221216.png)

### 4-1-e. CV / LB
CVã®ç²¾åº¦ã¯0.846ã¨ã‹ãªã‚Šé«˜ã„ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã§ãã¦ã„ã¾ã™ã€‚
ã§ã¯ã€submitã—ã¦ã¿ã‚‹ã¨ã©ã†ãªã‚‹ã§ã—ã‚‡ã†ã‹ï¼Ÿ
0.797ï¼æ‚ªããªã„ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ

![](https://storage.googleapis.com/zenn-user-upload/05f5e5a285ec-20221216.png)

<!-- ===================================================== -->
## 4-2. XGBoost

XGBoostã‚‚LightGBMã¨åŒã˜ãã€å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°æ±ºå®šæœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¨ãªã£ã¦ã„ã¾ã™ã€‚
kaggleãªã©ã®ãƒ‡ãƒ¼ã‚¿åˆ†æã‚³ãƒ³ãƒšã§ã¯LightGBMã¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆè¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ï¼‰ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚
XGBoostã¨LightGBMã®ä¸¡æ–¹ã¨ã‚‚ã€é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ãŒã€LightGBMãŒä¸€èˆ¬çš„ã«ã‚ˆã‚Šé«˜é€Ÿã«å‹•ä½œã™ã‚‹ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ï¼‰
```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import xgboost as xgb

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score, accuracy_score

import shap
# å¯è¦–åŒ–ã®ãŸã‚ã® javascript ã‚’èª­ã¿è¾¼ã¿
shap.initjs()
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼‰
```py
######### å»¶é•·æˆ¦ã«ãªã‚‹ã‹ã©ã†ã‹ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
SEED = 712

########################## ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df_train = pd.read_csv("../features/002_train.csv")
df_test = pd.read_csv("../features/002_test.csv")

df_train_lab = df_train.pop("Survived")
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
```py
XGB_PARAMS = {
    "objective": "binary:logistic",
    "eta": .005,
    "max_depth": 7,
    "eval_metric": "logloss",
    "tree_method": "gpu_hist",
}
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆå­¦ç¿’ï¼‰
```py
def fit_xgb(X: pd.DataFrame, y, cv, params, early_stopping_rounds: int = 20):
    oof_pred = np.zeros(len(X), dtype=np.float32)
    models = []
    scores = []

    for i, (idx_train, idx_valid) in enumerate(cv):
        x_train, y_train = X[X.index.isin(idx_train)], y[idx_train]
        x_valid, y_valid = X[X.index.isin(idx_valid)], y[idx_valid]

        ds_train = xgb.DMatrix(x_train, y_train)
        ds_valid = xgb.DMatrix(x_valid, y_valid)

        with Timer(prefix=f"fit ========== Fold: {i + 1}"):
            model = xgb.train(
                params,
                dtrain=ds_train,
                evals=[(ds_train, "train"), (ds_valid, "valid")],
                early_stopping_rounds=early_stopping_rounds,
                num_boost_round=500000,
                verbose_eval=200
            )

            pred_i = model.predict(ds_valid, ntree_limit=model.best_ntree_limit)
            oof_pred[idx_valid] = pred_i

            score = accuracy_score(y_valid, pred_i.round())
            print(f" - fold{i + 1} - {score:.4f}")

            scores.append(score)
            models.append(model)
        
    score = accuracy_score(y, oof_pred.round())
    print("=" * 50)
    print(f"FINISH: Whole Score: {score:.4f}")

    return oof_pred, models, score

fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
cv = fold.split(df_train, df_train_lab)
oof, models, score = fit_xgb(df_train, df_train_lab, cv, XGB_PARAMS)
```
:::

### 4-2-a. Cross Validationï¼ˆäº¤å·®æ¤œè¨¼ã€ä»¥é™ã§ã¯ CVï¼‰ã®çµæœ

```py
[0]	train-logloss:0.68989	valid-logloss:0.69082
[200]	train-logloss:0.35434	valid-logloss:0.47992
[400]	train-logloss:0.23235	valid-logloss:0.44055
[570]	train-logloss:0.18361	valid-logloss:0.43356
 - fold1 - 0.8156
fit ========== Fold: 1 1.983[s]
[0]	train-logloss:0.68983	valid-logloss:0.69045
[200]	train-logloss:0.35324	valid-logloss:0.46200
[390]	train-logloss:0.23367	valid-logloss:0.43595
 - fold2 - 0.8202
fit ========== Fold: 2 1.421[s]
[0]	train-logloss:0.69009	valid-logloss:0.69001
[200]	train-logloss:0.37238	valid-logloss:0.39419
[400]	train-logloss:0.25708	valid-logloss:0.31708
[600]	train-logloss:0.20065	valid-logloss:0.29060
[768]	train-logloss:0.17048	valid-logloss:0.28495
 - fold3 - 0.8933
fit ========== Fold: 3 2.520[s]
[0]	train-logloss:0.68977	valid-logloss:0.69069
[200]	train-logloss:0.34480	valid-logloss:0.49083
[354]	train-logloss:0.24156	valid-logloss:0.47992
 - fold4 - 0.7865
fit ========== Fold: 4 1.243[s]
[0]	train-logloss:0.68997	valid-logloss:0.69027
[200]	train-logloss:0.36193	valid-logloss:0.43049
[400]	train-logloss:0.24332	valid-logloss:0.36727
[553]	train-logloss:0.19982	valid-logloss:0.35849
 - fold5 - 0.8483
fit ========== Fold: 5 1.927[s]
==================================================
FINISH: Whole Score: 0.8328
```

### 4-2-b. äºˆæ¸¬å€¤ã®åˆ†å¸ƒã‚’è¦‹ã‚‹

:::detailsè©³ç´°ãªå®Ÿè£…
```py
plt.subplots(figsize=(8, 6))
ax = sns.distplot(oof, bins=30, label="train out of fold")
ax = sns.distplot(pred_prob, bins=30, label="test predict")
ax.legend()
plt.show()
```
:::

![](https://storage.googleapis.com/zenn-user-upload/407d62396d6f-20221216.png)

### 4-2-c. Shapã§ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’è¦‹ã‚‹
:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆShapã§ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’è¦‹ã‚‹ï¼‰
```py
explainer = shap.TreeExplainer(models[0])

shap_values = explainer.shap_values(df_train)
shap.summary_plot(shap_values=shap_values[0], features=df_train)
```
:::

![](https://storage.googleapis.com/zenn-user-upload/250182ca371f-20221216.png)

### 4-2-d. CV / LB

CVã®ç²¾åº¦ã¯0.833ã§ã—ãŸã€‚
ã§ã¯Submitã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚..0.790
LightGBMã¨éœè‰²ãªã„ç²¾åº¦ãŒå‡ºã¦ã„ã¾ã™ã­ï¼

![](https://storage.googleapis.com/zenn-user-upload/7d06dbfe0dd1-20221216.png)

<!-- ===================================================== -->
## 4-3. NN (Neural Network)

ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€è„³ã®æ§‹é€ ã¨æ©Ÿèƒ½ã‚’å‚è€ƒã«ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
"ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³"ã¨å‘¼ã°ã‚Œã‚‹å±¤ã‹ã‚‰ãªã‚‹ã‚‚ã®ã§ã€æƒ…å ±ã‚’å‡¦ç†ã—ã¦ä¼é€ã—ã¾ã™ã€‚

å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ä»–ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚„å¤–éƒ¨ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘å–ã‚Šã€ãã®å…¥åŠ›ã‚’ä½¿ç”¨ã—ã¦å‡ºåŠ›ä¿¡å·ã‚’ä»–ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚„å¤–éƒ¨ç’°å¢ƒã«å‡ºåŠ›ã—ã¾ã™ã€‚
å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å…¥åŠ›ã¨å‡ºåŠ›ã¯é€šå¸¸æ•°å€¤ã§ã‚ã‚Šã€å‡ºåŠ›ã‚’è¨ˆç®—ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã€Œæ´»æ€§åŒ–é–¢æ•°ã€ã¨å‘¼ã³ã¾ã™ã€‚

ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯éå¸¸ã«å¼·åŠ›ã§ã‚ã‚Šã€ç”»åƒã‚„éŸ³å£°èªè­˜ã€è‡ªç„¶è¨€èªå‡¦ç†ãªã©å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§æ´»ç”¨ã§ãã¾ã™ã€‚
å¤§è¦æ¨¡ã§è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‰±ã†ã®ã«ç‰¹ã«å„ªã‚Œã¦ãŠã‚Šã€ãƒ‡ãƒ¼ã‚¿å†…ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„é–¢ä¿‚æ€§ã«åŸºã¥ã„ã¦åˆ¤æ–­ã‚„äºˆæ¸¬ã‚’ã§ãã¾ã™ã€‚

ç‰¹å¾´é‡ã‚’å…¥åŠ›ã™ã‚‹éš›ã«æ¨™æº–åŒ–ï¼ˆå¹³å‡0åˆ†æ•£1ï¼‰ã™ã‚‹å‡¦ç†ã‚’ãŠã“ãªã„ã¾ã™ã€‚
ä»Šå›ã¯å…¥åŠ›å±¤+å‡ºåŠ›å±¤+éš ã‚Œå±¤ãŒ3å±¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ã¿ã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ï¼‰
```py
import pandas as pd
import numpy as np
from typing import List, Callable

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Dense, Input, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼‰
```py
SEED = 712

########################## ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df_train = pd.read_csv("../features/002_train.csv")
df_test = pd.read_csv("../features/002_test.csv")

df_train_lab = df_train.pop("Survived")
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆæ¨™æº–åŒ–ï¼‰
```py
class StanderdScale():
    def __init__(self) -> None:
        self.sc = StandardScaler()

    def fit(self, df_input: pd.DataFrame):
        self.sc.fit(df_input)
        return self.transform(df_input)
    
    def transform(self, df_input):
        return pd.DataFrame(data=self.sc.transform(df_input), columns=df_input.columns)

sc = StanderdScale()
df_train = sc.fit(df_train)
df_test = sc.transform(df_test)
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹é–¢æ•°ï¼‰
```py
class NNModel:
    """Neaural Networkãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰"""
    def __init__(
            self,
            input_size: int,
            hidden_sizes: List,
            output_size: int,
            activation: str = "relu",
            output_activation: str = "relu",
            add_BN: bool = True
            ) -> None:
        self.input = Input(shape=(input_size, ), name="input")
        self.output_size = Dense(output_size, name="output")
        self.add_BN = add_BN

        self.hidden_layers = []
        for idx, hidden_size in enumerate(hidden_sizes):
            if (idx+1) == len(self.hidden_layers):
                self.hidden_layers.append(Dense(hidden_size, output_activation, name=f"hidden_{idx+1}"))
                continue
            self.hidden_layers.append(Dense(hidden_size, activation, name=f"hidden_{idx+1}"))
    
    def build(self) -> Model:
        inputs = self.input
        for idx, hidden_layer in enumerate(self.hidden_layers):
            if idx == 0:
                x = hidden_layer(inputs)
                continue

            x = BatchNormalization()(x)
            x = hidden_layer(x)
        outputs = self.output_size(x)
        return Model(inputs, outputs)
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼‰
```py
def plot_history(hist):
    # æå¤±å€¤(Loss)ã®é·ç§»ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.plot(hist.history['loss'],label="train set")
    plt.plot(hist.history['val_loss'],label="test set")
    plt.title('model loss')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.show()

def fit_nn(
        X,
        y,
        cv, 
        metrics: List,
        score_func: Callable[[np.ndarray, np.ndarray], float],
        NNModel: Model, 
        NN_MODEL_PARAMS: dict,
        n_epoch: int = 500, 
        loss: str = "mse",
        optimizer = "adam",
        verbose: int = -1,
        eary_stopping_rounds: int = 50,
        ):
    oof_pred = np.zeros(len(X), dtype=np.float32)
    models = []
    scores = []

    for i, (idx_train, idx_valid) in enumerate(cv):
        x_train, y_train = X[X.index.isin(idx_train)], y[idx_train]
        x_valid, y_valid = X[X.index.isin(idx_valid)], y[idx_valid]

        model = NNModel(**NN_MODEL_PARAMS)
        model = model.build()
        model.compile(
            optimizer,
            loss,
            metrics
        )
        history = model.fit(
                x_train,
                y_train,
                epochs=n_epoch,
                verbose=verbose,
                validation_data=(x_valid, y_valid),
                callbacks=[EarlyStopping(patience=eary_stopping_rounds)]
            )

        plot_history(history)

        oof = model.predict(x_valid)
        oof_pred[idx_valid] = oof.flatten()
        models.append(model)
        
        print("-"*50)
        if score_func.__name__ == "accuracy_score":
            print(f"score {i+1}:\t {score_func(y_valid, np.round(oof).astype(int))}")
        else:
            print(f"score {i+1}:\t {score_func(y_valid, oof)}")

    print("*"*50)
    if score_func.__name__ == "accuracy_score":
        score = score_func(y, np.round(oof_pred).astype(int))
    else:
        score = score_func(y, oof_pred)
    print(f"score {i+1}:\t {score}")

    return models, oof_pred, score
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆå­¦ç¿’ï¼‰
```py
NN_MODEL_PARAMS = {
    "input_size": len(df_train.columns),
    "hidden_sizes": [512, 256, 128, 64, 32],
    "output_size": 1,
    "activation": "relu",
    "output_activation": "sigmoid",
    "add_BN": True
}

NN_FIT_PARAMS = {
    "NNModel": NNModel,
    "NN_MODEL_PARAMS": NN_MODEL_PARAMS,
    "metrics": ["accuracy"],
    "score_func": accuracy_score,
    "n_epoch": 1000,
    "loss": "mse",
    "optimizer": Adam(learning_rate=.001),
    "verbose": 0,
    "eary_stopping_rounds": 50
}

fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
cv = fold.split(df_train, df_train_lab)
models, oof, score = fit_nn(X=df_train, y=df_train_lab, cv=cv, **NN_FIT_PARAMS)

# k å€‹ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡ (predict_proba) ã‚’ä½œæˆ. shape = (k, N_test, n_classes).
pred_prob = np.array([model.predict(df_test).flatten() for model in models])
print(f"1. shape: {pred_prob.shape}")

# k å€‹ã®ãƒ¢ãƒ‡ãƒ«ã®å¹³å‡ã‚’è¨ˆç®—
pred_prob = np.mean(pred_prob, axis=0) # axis=0 ãªã®ã§ shape ã® `k` ãŒæ½°ã‚Œã‚‹ 
print(f"2. shape: {pred_prob.shape}")
```
:::

### 4-3-a. Cross Validationï¼ˆäº¤å·®æ¤œè¨¼ã€ä»¥é™ã§ã¯ CVï¼‰ã®çµæœ
```py
6/6 [==============================] - 0s 1ms/step
--------------------------------------------------
score 1:	 0.7877094972067039
6/6 [==============================] - 0s 1ms/step
--------------------------------------------------
score 2:	 0.7752808988764045
6/6 [==============================] - 0s 1ms/step
--------------------------------------------------
score 3:	 0.8876404494382022
6/6 [==============================] - 0s 999us/step
--------------------------------------------------
score 4:	 0.8370786516853933
6/6 [==============================] - 0s 1ms/step
--------------------------------------------------
score 5:	 0.8426966292134831
**************************************************
score 5:	 0.8260381593714927
```

### 4-3-b. äºˆæ¸¬å€¤ã®åˆ†å¸ƒã‚’è¦‹ã‚‹

:::detailsè©³ç´°ãªå®Ÿè£…
plt.subplots(figsize=(8, 6))
ax = sns.distplot(oof, bins=30, label="train out of fold")
ax = sns.distplot(pred_prob, bins=30, label="test predict")
ax.legend()
plt.show()
:::

![](https://storage.googleapis.com/zenn-user-upload/c9540b9c3658-20221216.png)

### 4-3-c. CV / LB

CVã®ç²¾åº¦ã¯0.826ã§ã—ãŸã€‚
ã§ã¯Submitã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚..0.754
å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã™ã‚‹ã¨è‹¥å¹²ç²¾åº¦ã¯åŠ£ã‚‹ã‚ˆã†ã§ã™ã€‚
å±¤ã®æ•°ã‚„å…¥åŠ›ã‚µã‚¤ã‚ºãªã©ã€èª¿æ•´ã™ã¹ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤šã„ãŸã‚ã€æœ€é©åŒ–ã«ã¯æ™‚é–“ã‚’è¦ã—ãã†ã§ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/9f2e64ff858b-20221216.png)

<!-- ===================================================== -->
## 4-4. SVM

SVMã¯ã€åˆ†é¡ã‚„å›å¸°ã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã§ãã‚‹æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã™ã€‚
ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã®è¦ç´ ã‚’æœ€å¤§é™ã«åˆ†é›¢ã™ã‚‹ã‚ˆã†ã«å®Ÿè£…ã•ã‚Œã¾ã™ã€‚
ã¾ãŸã€é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®æ‰±ã„ã‚‚å¯èƒ½ã§ã€å¤–ã‚Œå€¤ã«ã‚‚å¼·ã„ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ï¼‰
```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score, accuracy_score
from sklearn.preprocessing import StandardScaler

from sklearn.svm import SVC
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼‰
```py
SEED = 712

########################## ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df_train = pd.read_csv("../features/002_train.csv")
df_test = pd.read_csv("../features/002_test.csv")

df_train_lab = df_train.pop("Survived")
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆæ¨™æº–åŒ–ï¼‰
```py
class StanderdScale():
    def __init__(self) -> None:
        self.sc = StandardScaler()

    def fit(self, df_input: pd.DataFrame):
        self.sc.fit(df_input)
        return self.transform(df_input)
    
    def transform(self, df_input):
        return pd.DataFrame(data=self.sc.transform(df_input), columns=df_input.columns)

sc = StanderdScale()
df_train = sc.fit(df_train)
df_test = sc.transform(df_test)
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆå­¦ç¿’ï¼‰
```py
def fit_svm(X: pd.DataFrame, y, cv):
    oof_pred = np.zeros(len(X), dtype=np.float32)
    models = []
    scores = []

    for i, (idx_train, idx_valid) in enumerate(cv):
        x_train, y_train = X[X.index.isin(idx_train)], y[idx_train]
        x_valid, y_valid = X[X.index.isin(idx_valid)], y[idx_valid]

        with Timer(prefix=f"fit ========== Fold: {i + 1}"):
            model = SVC()
            model.fit(x_train, y_train)

            pred_i = model.predict(x_valid)
            oof_pred[idx_valid] = pred_i

            score = accuracy_score(y_valid, pred_i.round())
            print(f" - fold{i + 1} - {score:.4f}")

            scores.append(score)
            models.append(model)
        
    score = accuracy_score(y, oof_pred.round())
    print("=" * 50)
    print(f"FINISH: Whole Score: {score:.4f}")

    return oof_pred, models, score

fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
cv = fold.split(df_train, df_train_lab)
oof, models, score = fit_svm(df_train, df_train_lab, cv)
```
:::

### 4-4-a. Cross Validationï¼ˆäº¤å·®æ¤œè¨¼ã€ä»¥é™ã§ã¯ CVï¼‰ã®çµæœ
```py
 - fold1 - 0.8324
fit ========== Fold: 1 0.019[s]
 - fold2 - 0.8090
fit ========== Fold: 2 0.017[s]
 - fold3 - 0.8764
fit ========== Fold: 3 0.019[s]
 - fold4 - 0.7921
fit ========== Fold: 4 0.017[s]
 - fold5 - 0.8315
fit ========== Fold: 5 0.018[s]
==================================================
FINISH: Whole Score: 0.8283
```

### 4-4-b. äºˆæ¸¬å€¤ã®åˆ†å¸ƒã‚’è¦‹ã‚‹

:::detailsè©³ç´°ãªå®Ÿè£…
```py
plt.subplots(figsize=(8, 6))
ax = sns.distplot(oof, bins=30, label="train out of fold")
ax = sns.distplot(pred_prob, bins=30, label="test predict")
ax.legend()
plt.show()
```
:::

![](https://storage.googleapis.com/zenn-user-upload/3c7cd32cf3a7-20221216.png)

### 4-4-c. CV / LB

CVã®ç²¾åº¦ã¯0.828ã§ã—ãŸã€‚
ã§ã¯Submitã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚..0.766
CV / LBã¨ã‚‚ã«NNã‚ˆã‚Šã‚‚è‹¥å¹²é«˜ã„ç²¾åº¦ãŒå‡ºã¦ã„ã¾ã™ã€‚
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ•°ã‚‚å°‘ãªãã€å®Ÿè£…ã‚‚ç°¡å˜ãªã®ã§ã€ä½¿ã„å‹æ‰‹ã¯è‰¯ã•ãã†ã§ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/4fe8255c6348-20221216.png)

<!-- ===================================================== -->
## 4-5. k-NN

k-NNã¯kè¿‘å‚æ³•ã¨ã‚‚å‘¼ã°ã‚Œã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãã®è¿‘å‚ã®kå€‹ã®ãƒ‡ãƒ¼ã‚¿ã®è¦ç´ ã‚’è¦‹ã¤ã‘ã¾ã™ã€‚
kå€‹ã®ãƒ‡ãƒ¼ã‚¿ã®è¦ç´ ã®å¤šæ•°æ±ºã«åŸºã¥ã„ã¦ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚

ãƒ‡ãƒ¼ã‚¿ãŒéå¸¸ã«å¤§ãã„å ´åˆã‚„ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè†¨å¤§ãªå ´åˆã«ã¯é©ã—ã¦ã„ã‚‹ã¨ã¯ã„ãˆãªã„ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
ã¾ãŸã€ç‰¹å¾´é‡ã®æ•°ãŒå¤šã„å ´åˆã«ã‚‚ã€äºˆæ¸¬ã®æ­£ç¢ºæ€§ã«ãŠã„ã¦ä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
ãã®ãŸã‚ã€k-NNã¯å°è¦æ¨¡ã§ç‰¹å¾´é‡ã®æ•°ãŒå°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ‰åŠ¹ã§ã™ã€‚

ä»Šå›ã¯ã€kï¼ˆè¿‘å‚æ•°ï¼‰ã‚’2ã‹ã‚‰50ã¾ã§æ¢ç´¢ã—ã¦ã¿ã¾ã™ã€‚

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ï¼‰
```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score, accuracy_score
from sklearn.preprocessing import StandardScaler

from sklearn.neighbors import KNeighborsClassifier
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼‰
```py
SEED = 712

########################## ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df_train = pd.read_csv("../features/002_train.csv")
df_test = pd.read_csv("../features/002_test.csv")

df_train_lab = df_train.pop("Survived")
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆæ¨™æº–åŒ–ï¼‰
```py
class StanderdScale():
    def __init__(self) -> None:
        self.sc = StandardScaler()

    def fit(self, df_input: pd.DataFrame):
        self.sc.fit(df_input)
        return self.transform(df_input)
    
    def transform(self, df_input):
        return pd.DataFrame(data=self.sc.transform(df_input), columns=df_input.columns)

sc = StanderdScale()
df_train = sc.fit(df_train)
df_test = sc.transform(df_test)
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆãƒ¢ãƒ‡ãƒ«ï¼‰
```py
def fit_knn(X: pd.DataFrame, y, cv, k: int = 6):
    oof_pred = np.zeros(len(X), dtype=np.float32)
    models = []
    scores = []

    for i, (idx_train, idx_valid) in enumerate(cv):
        x_train, y_train = X[X.index.isin(idx_train)], y[idx_train]
        x_valid, y_valid = X[X.index.isin(idx_valid)], y[idx_valid]

        with Timer(prefix=f"fit ========== Fold: {i + 1}"):
            model = KNeighborsClassifier(n_neighbors=k)
            model.fit(x_train, y_train)

            pred_i = model.predict(x_valid)
            oof_pred[idx_valid] = pred_i

            score = accuracy_score(y_valid, pred_i.round())
            print(f" - fold{i + 1} - {score:.4f}")

            scores.append(score)
            models.append(model)
        
    score = accuracy_score(y, oof_pred.round())
    print("=" * 50)
    print(f"FINISH: Whole Score: {score:.4f}")

    return oof_pred, models, score
```
:::

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆkã®æ¢ç´¢ï¼‰
```py
scores = []
for k in range(1, 51):
    fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
    cv = fold.split(df_train, df_train_lab)
    oof, models, score = fit_knn(df_train, df_train_lab, cv, k)
    scores.append(score)

plt.subplots(figsize=(12, 6))
g = sns.lineplot(x=range(1, 51), y=scores)
g.grid()
plt.show()
```
:::
```py
print(np.argmax(scores)+1)
```
```
14
```

CVã«ã‚ˆã‚‹æœ€é©ãªè¿‘å‚æ•°ã‚’æ¢ç´¢ã—ãŸçµæœã€k=14ã®ã¨ããŒæœ€å¤§ã¨ãªã‚Šã¾ã—ãŸã€‚

![](https://storage.googleapis.com/zenn-user-upload/5545f6458821-20221216.png)

:::detailsè©³ç´°ãªå®Ÿè£…ï¼ˆå­¦ç¿’ï¼‰
```py
fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
cv = fold.split(df_train, df_train_lab)
oof, models, score = fit_knn(df_train, df_train_lab, cv, k=np.argmax(scores)+1)
```
:::

### 4-5-a. Cross Validationï¼ˆäº¤å·®æ¤œè¨¼ã€ä»¥é™ã§ã¯ CVï¼‰ã®çµæœ
```py
 - fold1 - 0.8436
fit ========== Fold: 1 0.009[s]
 - fold2 - 0.8539
fit ========== Fold: 2 0.014[s]
 - fold3 - 0.8652
fit ========== Fold: 3 0.011[s]
 - fold4 - 0.8202
fit ========== Fold: 4 0.010[s]
 - fold5 - 0.8371
fit ========== Fold: 5 0.012[s]
==================================================
FINISH: Whole Score: 0.8440
```

### 4-5-b. äºˆæ¸¬å€¤ã®åˆ†å¸ƒã‚’è¦‹ã‚‹

:::detailsè©³ç´°ãªå®Ÿè£…
```py
plt.subplots(figsize=(8, 6))
ax = sns.distplot(oof, bins=30, label="train out of fold")
ax = sns.distplot(pred_prob, bins=30, label="test predict")
ax.legend()
plt.show()
```
:::

![](https://storage.googleapis.com/zenn-user-upload/9ded09b473cd-20221216.png)

### 4-5-c. CV / LB

CVã®ç²¾åº¦ã¯0.844ã§ã—ãŸã€‚
ã§ã¯Submitã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚..0.761
CVã®ç²¾åº¦ã¯LightGBMã«æ¬¡ã„ã§é«˜ã„ã§ã™ãŒã€LBãŒã‚ã¾ã‚Šè‰¯ãã‚ã‚Šã¾ã›ã‚“ã­ã€‚
Trust CVï¼ˆäº¤å·®æ¤œè¨¼ã‚’ä¿¡ã˜ã‚ˆï¼‰ã¨ã„ã†æ–‡è„ˆã§ã¯ã‚ã‚‹ç¨‹åº¦ç²¾åº¦ãŒå‡ºã¦ã„ã‚‹ã¨ã„ã†åˆ¤æ–­ã§ã‚‚è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

![](https://storage.googleapis.com/zenn-user-upload/b46090fe03e1-20221216.png)

# 5. ã¾ã¨ã‚
ä»Šå›ã¯5ã¤ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBM,XGBoostã€NNã€SVMã€k-NNï¼‰ã«å¯¾ã—ã¦CVã¨LBã‚’æ¯”è¼ƒã—ã¦ã¿ã¾ã—ãŸã€‚
ã¾ã¨ã‚ã¯ä»¥ä¸‹ã®é€šã‚Šã«ãªã‚Šã¾ã™ã€‚

| Model    | CV Accuracy | LB Accuracy |
|----------|-------------|-------------|
| LightGBM | 0.846       | 0.797       |
| XGBoost  | 0.833       | 0.790       |
| NN       | 0.826       | 0.754       |
| SVM      | 0.828       | 0.766       |
| k-NN     | 0.844       | 0.761       |


GBDTç³»ã®ãƒ¢ãƒ‡ãƒ«ã¯å®‰å®šã—ã¦ç²¾åº¦ãŒå‡ºã¦ã„ã¾ã™ã­ã€‚
ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã—ã¦æå‡ºã™ã‚‹ã¨ã•ã‚‰ã«è‰¯ã„ç²¾åº¦ãŒå¾—ã‚‰ã‚Œãã†ã§ã™ã­ï¼

ä»Šå›ã¯ã“ã‚“ãªã¨ã“ã‚ã§ï¼